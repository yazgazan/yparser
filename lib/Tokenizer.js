// Generated by CoffeeScript 1.7.1
(function() {
  var Parser, Token, Tokenizer,
    __hasProp = {}.hasOwnProperty,
    __extends = function(child, parent) { for (var key in parent) { if (__hasProp.call(parent, key)) child[key] = parent[key]; } function ctor() { this.constructor = child; } ctor.prototype = parent.prototype; child.prototype = new ctor(); child.__super__ = parent.prototype; return child; };

  Parser = require("./Parser");

  Token = (function() {
    function Token(data, type) {
      this.data = data;
      this.type = type != null ? type : null;
      this.line = null;
      this.pos = null;
    }

    Token.prototype.setLine = function(line) {
      this.line = line;
      return this.line;
    };

    Token.prototype.setPos = function(pos) {
      this.pos = pos;
      return this.pos;
    };

    return Token;

  })();

  Tokenizer = (function(_super) {
    __extends(Tokenizer, _super);

    function Tokenizer() {
      this.tokRules = new Object;
      this.tokens = [];
      this.breakOnUnknownToken = false;
      Tokenizer.__super__.constructor.call(this);
    }

    Tokenizer.prototype.addTokRule = function(type, func) {
      return this.tokRules[type] = func;
    };

    Tokenizer.prototype.doToken = function(pos, line, backupPos) {
      var data, func, rule, type, _ref;
      data = null;
      type = null;
      _ref = this.tokRules;
      for (rule in _ref) {
        func = _ref[rule];
        if (func.call(this)) {
          data = this.endCap('tok');
          type = rule;
          break;
        }
        this.cpos = pos;
        this.line = line;
        this.pos = backupPos;
      }
      return [data, type];
    };

    Tokenizer.prototype.handleUnknownToken = function(type, data, line) {
      var msg, _cursor, _line;
      if (type === null) {
        this.startCap('tok');
        this.readAny();
        data = this.endCap('tok');
        if (this.breakOnUnknownToken === true) {
          _line = this.reconstructLine(line, data);
          _cursor = this._generateCursor(this.cpos);
          msg = "unkown token '" + data + "':\n" + _line + "\n" + _cursor;
          throw Error(msg);
        }
      }
      return data;
    };

    Tokenizer.prototype.tokenize = function() {
      var backupPos, data, line, pos, token, type, _ref;
      this.tokens = [];
      while (!this.isEnd()) {
        line = this.line;
        pos = this.cpos;
        backupPos = this.pos;
        this.startCap('tok');
        _ref = this.doToken(pos, line, backupPos), data = _ref[0], type = _ref[1];
        data = this.handleUnknownToken(type, data, line);
        token = new Token(data, type);
        token.setLine(line);
        token.setPos(pos);
        this.tokens.push(token);
      }
      return null;
    };

    Tokenizer.prototype._generateCursor = function(n) {
      var i, ret, _i, _ref;
      ret = "";
      for (i = _i = 1, _ref = n - 2; 1 <= _ref ? _i < _ref : _i > _ref; i = 1 <= _ref ? ++_i : --_i) {
        ret += " ";
      }
      ret += "^";
      return ret;
    };

    Tokenizer.prototype.reconstructLine = function(line, data) {
      var backupPos, tok, _i, _len, _line, _ref;
      if (data == null) {
        data = "";
      }
      _line = "";
      backupPos = this.pos;
      _ref = this.tokens;
      for (_i = 0, _len = _ref.length; _i < _len; _i++) {
        tok = _ref[_i];
        if (tok.line === line) {
          if (tok.data !== void 0) {
            _line += (tok.data.split("\n"))[0];
          }
        }
      }
      _line += data;
      while (!(this.readEOL() || this.isEnd())) {
        if (this.buf[this.pos] !== void 0) {
          _line += this.buff[this.pos];
        }
        ++this.pos;
      }
      this.pos = backupPos;
      return _line;
    };

    Tokenizer.prototype.setBreakOnUnknownToken = function(breakOnUnknownToken) {
      this.breakOnUnknownToken = breakOnUnknownToken != null ? breakOnUnknownToken : true;
      return this.breakOnUnknownToken;
    };

    Tokenizer.prototype.lastToken = function() {
      return this.tokens.slice(-1)[0];
    };

    return Tokenizer;

  })(Parser);

  Tokenizer.Token = Token;

  Tokenizer.Parser = Parser;

  module.exports = Tokenizer;

}).call(this);
