// Generated by CoffeeScript 1.6.3
(function() {
  var Token, Tokenizer, assert;

  Tokenizer = require('../lib/Tokenizer');

  Token = Tokenizer.Token;

  assert = function(expected, actual) {
    var err;
    if ((expected !== void 0) && (actual !== void 0)) {
      if (expected === actual) {
        return;
      }
    }
    err = new Error;
    err.expected = "" + expected;
    err.actual = "" + actual;
    throw err;
  };

  describe("Tokenizer", function() {
    describe("#constructor", function() {
      return it("should construct a clean Tokenizer", function() {
        var parser;
        parser = new Tokenizer;
        assert("", parser.buff);
        assert(0, parser.pos);
        assert(1, parser.line);
        assert(1, parser.cpos);
        assert(false, parser.breakOnUnknownToken);
        return assert(0, parser.tokens.length);
      });
    });
    describe("#addTokRule", function() {
      return it("should add tu rule to the @tokRules object. dont check the type", function() {
        var parser;
        parser = new Tokenizer;
        assert(42, parser.addTokRule("test1", 42));
        return assert(42, parser.tokRules["test1"]);
      });
    });
    describe("#tokenize", function() {
      return it("should tokenize string given the added rules", function() {
        var parser, test_str;
        test_str = "blah42 23  haha";
        parser = new Tokenizer;
        parser.addTokRule("ha", function() {
          if (!this.readText("ha")) {
            return false;
          }
          while (this.readText("ha")) {
            null;
          }
          return true;
        });
        parser.addTokRule("id", function() {
          return this.readIdentifier();
        });
        parser.addTokRule("int", function() {
          return this.readInt();
        });
        parser.addTokRule("spaces", function() {
          return this.readSpaces();
        });
        parser.loadString(test_str);
        parser.tokenize();
        assert(5, parser.tokens.length);
        assert("id", parser.tokens[0].type);
        assert("blah42", parser.tokens[0].data);
        assert("spaces", parser.tokens[1].type);
        assert("int", parser.tokens[2].type);
        assert("23", parser.tokens[2].data);
        assert("spaces", parser.tokens[3].type);
        assert("ha", parser.tokens[4].type);
        return assert("haha", parser.tokens[4].data);
      });
    });
    describe("#reconstructLine", function() {
      return it("should reconstruct the line given the provided line number", function() {
        var parser, test_str;
        test_str = "blah42 \n23  haha";
        parser = new Tokenizer;
        parser.addTokRule("ha", function() {
          if (!this.readText("ha")) {
            return false;
          }
          while (this.readText("ha")) {
            null;
          }
          return true;
        });
        parser.addTokRule("id", function() {
          return this.readIdentifier();
        });
        parser.addTokRule("int", function() {
          return this.readInt();
        });
        parser.addTokRule("spaces", function() {
          if (!(this.readSpaces() || this.readEOL())) {
            return false;
          }
          while (this.readSpaces() || this.readEOL()) {
            null;
          }
          return true;
        });
        parser.loadString(test_str);
        parser.tokenize();
        return assert((test_str.split("\n"))[0], parser.reconstructLine(1));
      });
    });
    return describe("#lastToken", function() {
      return it("should should return the last token", function() {
        var parser, test_str, token;
        test_str = "blah42 \n23  haha";
        parser = new Tokenizer;
        parser.addTokRule("ha", function() {
          if (!this.readText("ha")) {
            return false;
          }
          while (this.readText("ha")) {
            null;
          }
          return true;
        });
        parser.addTokRule("id", function() {
          return this.readIdentifier();
        });
        parser.addTokRule("int", function() {
          return this.readInt();
        });
        parser.addTokRule("spaces", function() {
          if (!(this.readSpaces() || this.readEOL())) {
            return false;
          }
          while (this.readSpaces() || this.readEOL()) {
            null;
          }
          return true;
        });
        parser.loadString(test_str);
        parser.tokenize();
        token = parser.lastToken();
        assert("ha", token.type);
        assert("haha", token.data);
        assert(2, token.line);
        return assert(5, token.pos);
      });
    });
  });

}).call(this);
